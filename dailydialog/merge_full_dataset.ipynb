{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67de25b8",
   "metadata": {},
   "source": [
    "# Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b3f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from util import get_dataframe_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = get_dataframe_from_json(\"dialogues.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39e5e7",
   "metadata": {},
   "source": [
    "## Red dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df.loc[red_df['emotion'] == 'anger',  'hat'] = 'red'\n",
    "red_df.loc[red_df['emotion'] == 'fear', 'hat'] = 'red'\n",
    "red_df.loc[red_df['emotion'] == 'disgust','hat'] = 'red'\n",
    "red_df.loc[red_df['emotion'] == 'sadness','hat'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7af97900",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_df = red_df[red_df['hat'] == 'red']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288d312",
   "metadata": {},
   "source": [
    "## Black and White\n",
    "- each line is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1008858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bw_df = pd.read_json(\"../Automated Labeling/Black_White_Hat/dataset_with_bloom.json\", lines=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82c2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert value \"black\" in the hat column where the bloom_label is \"Analysis\"\n",
    "bw_df.loc[bw_df['bloom_label'] == 'Analysis',  'hat'] = 'black'\n",
    "bw_df.loc[bw_df['bloom_label'] == 'Knowledge', 'hat'] = 'white'\n",
    "bw_df.loc[bw_df['bloom_label'] == 'Evaluation','hat'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d8b4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat\n",
      "          8277\n",
      "black     4916\n",
      "white    37734\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(bw_df.groupby('hat').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8939639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows where the column 'hat' has value 'black'\n",
    "black_df = bw_df[bw_df['hat'] == 'black']\n",
    "white_df = bw_df[bw_df['hat'] == 'white']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d6e3f",
   "metadata": {},
   "source": [
    "## Yellow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2c199fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json /home/atlas/hlt/HLT/Automated Labeling/Yellow Hat/dataset_with_bloom_optimism.json\n",
    "yellow_df = pd.read_json(\"../Automated Labeling/Yellow Hat/dataset_with_bloom_optimism.json\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68370ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_df.loc[yellow_df['optimism_label'] == 'optimist','hat'] = 'yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abf9fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat\n",
      "          50491\n",
      "yellow      436\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(yellow_df.groupby('hat').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b91c661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_df.loc[yellow_df['emotion'] == 'happiness','hat'] = 'yellow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dafe9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat\n",
      "          42668\n",
      "yellow     8259\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(yellow_df.groupby('hat').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d4812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_df = yellow_df[yellow_df['hat'] == 'yellow']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579202bd",
   "metadata": {},
   "source": [
    "## Green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a94797",
   "metadata": {},
   "outputs": [],
   "source": "green_df = pd.read_csv(\"../Automated Labeling/Green Hat/Lm Studio Labeling/hat_preds.csv\", encoding=\"utf-8\")"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f782295",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_df.loc[green_df['hat'] == 'Y','hat'] = 'green'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33632861",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_df = green_df[green_df['hat'] == 'green']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c30a4",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba0bfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only column utterance and hat\n",
    "green_df = green_df[['utterance', 'hat']]\n",
    "red_df = red_df[['utterance', 'hat']]\n",
    "white_df = white_df[['utterance', 'hat']]\n",
    "black_df = black_df[['utterance', 'hat']]\n",
    "yellow_df = yellow_df[['utterance', 'hat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87ab6772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red Hat DataFrame size: (2698, 2)\n",
      "Black Hat DataFrame size: (4916, 2)\n",
      "White Hat DataFrame size: (37734, 2)\n",
      "Yellow Hat DataFrame size: (8259, 2)\n",
      "Green Hat DataFrame size: (16365, 2)\n"
     ]
    }
   ],
   "source": [
    "# show size of each dataframe\n",
    "print(\"Red Hat DataFrame size:\", red_df.shape)\n",
    "print(\"Black Hat DataFrame size:\", black_df.shape)\n",
    "print(\"White Hat DataFrame size:\", white_df.shape)\n",
    "print(\"Yellow Hat DataFrame size:\", yellow_df.shape)\n",
    "print(\"Green Hat DataFrame size:\", green_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60fcbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the dataframes into one dataframe\n",
    "merged_df = pd.concat([red_df, black_df, white_df, yellow_df, green_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5610f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the duplicates utterances in the merged dataframe, create a new column with the number of rows for each utterance\n",
    "merged_df['count'] = merged_df.groupby('utterance')['utterance'].transform('size')\n",
    "# sort merged_df by count and utterance\n",
    "merged_df = merged_df.sort_values(by=['count', 'utterance'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0b1d8354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all the duplicates in the merged dataframe\n",
    "merged_df = merged_df.drop_duplicates(subset=['utterance'], keep='first')\n",
    "# drop the count column\n",
    "merged_df = merged_df.drop(columns=['count'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bcf78dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hat\n",
      "black      4192\n",
      "green      7997\n",
      "red        2408\n",
      "white     30032\n",
      "yellow     1045\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# show distribution of the hat column\n",
    "print(merged_df.groupby('hat').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3279c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep up to 1000 samples for each hat, pick randomly\n",
    "red_df = merged_df[merged_df['hat'] == 'red'].sample(n=1000, random_state=1)\n",
    "black_df = merged_df[merged_df['hat'] == 'black'].sample(n=1000, random_state=1)\n",
    "white_df = merged_df[merged_df['hat'] == 'white'].sample(n=1000, random_state=1)\n",
    "yellow_df = merged_df[merged_df['hat'] == 'yellow'].sample(n=1000, random_state=1)\n",
    "green_df = merged_df[merged_df['hat'] == 'green'].sample(n=1000, random_state=1)\n",
    "\n",
    "# merge all the dataframes into one dataframe\n",
    "merged_df = pd.concat([red_df, black_df, white_df, yellow_df, green_df], ignore_index=True)\n",
    "# shuffle the dataframe\n",
    "merged_df = merged_df.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37e09a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe to a csv file\n",
    "merged_df.to_csv(\"final_dataset.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e7b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
