{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:13.912701Z",
     "start_time": "2025-05-20T09:49:09.189204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from bert_util import bert_tokenize_data, tensor_train_test_split, train_bert_model, model_predict, get_data_loader, \\\n",
    "    calculate_accuracy\n",
    "from util import get_dataframe_from_json\n",
    "\n",
    "os.environ[\"USE_TF\"] = \"0\""
   ],
   "id": "e79ad018e19671f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emiliano/Desktop/Università/Human Language Technologies/Project/HLT Project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-20 11:49:12.346902: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-20 11:49:12.354106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747734552.362872   32772 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747734552.365226   32772 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747734552.371669   32772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747734552.371679   32772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747734552.371680   32772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747734552.371681   32772 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-20 11:49:12.374627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:14.191219Z",
     "start_time": "2025-05-20T09:49:14.076798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hld = get_dataframe_from_json('./hand_labeled/hand_labelled_dataset.json')\n",
    "hld"
   ],
   "id": "4d6cb2e52215c782",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      turn                                          utterance     emotion  \\\n",
       "0        0       I'm so angry . I feel like killing someone .       anger   \n",
       "1        1                                Calm down . __eou__  no_emotion   \n",
       "2        0  I was just about to go to bed when the telepho...  no_emotion   \n",
       "3        1                                       Who was it ?  no_emotion   \n",
       "4        2  Kate . She said she was too excited to go to s...  no_emotion   \n",
       "...    ...                                                ...         ...   \n",
       "1012     6  I want to live abroad and learn to speak a dif...  no_emotion   \n",
       "1013     7              I'm really sorry . But I understand .  no_emotion   \n",
       "1014     8                      Thank you , manager . __eou__  no_emotion   \n",
       "1015     0                            I fired Mr . Li today .  no_emotion   \n",
       "1016     1                          That's terrible . __eou__     sadness   \n",
       "\n",
       "             act    hat  \n",
       "0         inform    red  \n",
       "1         inform    red  \n",
       "2         inform  white  \n",
       "3       question  white  \n",
       "4         inform  white  \n",
       "...          ...    ...  \n",
       "1012      inform  white  \n",
       "1013  commissive  white  \n",
       "1014      inform  white  \n",
       "1015      inform  white  \n",
       "1016      inform  black  \n",
       "\n",
       "[1017 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm so angry . I feel like killing someone .</td>\n",
       "      <td>anger</td>\n",
       "      <td>inform</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Calm down . __eou__</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I was just about to go to bed when the telepho...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Who was it ?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Kate . She said she was too excited to go to s...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>6</td>\n",
       "      <td>I want to live abroad and learn to speak a dif...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>7</td>\n",
       "      <td>I'm really sorry . But I understand .</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>commissive</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>8</td>\n",
       "      <td>Thank you , manager . __eou__</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0</td>\n",
       "      <td>I fired Mr . Li today .</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1</td>\n",
       "      <td>That's terrible . __eou__</td>\n",
       "      <td>sadness</td>\n",
       "      <td>inform</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:14.257897Z",
     "start_time": "2025-05-20T09:49:14.254120Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "da62261522bfed02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:14.352791Z",
     "start_time": "2025-05-20T09:49:14.346965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "\n",
    "reverse_hat_map = {v: k for k, v in hat_map.items()}\n",
    "hld['hat'] = hld['hat'].apply(lambda x: reverse_hat_map[x])"
   ],
   "id": "53d408cc997ae229",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:14.478478Z",
     "start_time": "2025-05-20T09:49:14.465649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hld\n",
    "# Load datasetdf = pd.read_csv(\"tweets_annotation.csv\")  # must have 'text' and 'score' columns"
   ],
   "id": "79a23660b4fb347e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      turn                                          utterance     emotion  \\\n",
       "0        0       I'm so angry . I feel like killing someone .       anger   \n",
       "1        1                                Calm down . __eou__  no_emotion   \n",
       "2        0  I was just about to go to bed when the telepho...  no_emotion   \n",
       "3        1                                       Who was it ?  no_emotion   \n",
       "4        2  Kate . She said she was too excited to go to s...  no_emotion   \n",
       "...    ...                                                ...         ...   \n",
       "1012     6  I want to live abroad and learn to speak a dif...  no_emotion   \n",
       "1013     7              I'm really sorry . But I understand .  no_emotion   \n",
       "1014     8                      Thank you , manager . __eou__  no_emotion   \n",
       "1015     0                            I fired Mr . Li today .  no_emotion   \n",
       "1016     1                          That's terrible . __eou__     sadness   \n",
       "\n",
       "             act  hat  \n",
       "0         inform    0  \n",
       "1         inform    0  \n",
       "2         inform    1  \n",
       "3       question    1  \n",
       "4         inform    1  \n",
       "...          ...  ...  \n",
       "1012      inform    1  \n",
       "1013  commissive    1  \n",
       "1014      inform    1  \n",
       "1015      inform    1  \n",
       "1016      inform    2  \n",
       "\n",
       "[1017 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm so angry . I feel like killing someone .</td>\n",
       "      <td>anger</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Calm down . __eou__</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I was just about to go to bed when the telepho...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Who was it ?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Kate . She said she was too excited to go to s...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>6</td>\n",
       "      <td>I want to live abroad and learn to speak a dif...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>7</td>\n",
       "      <td>I'm really sorry . But I understand .</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>8</td>\n",
       "      <td>Thank you , manager . __eou__</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0</td>\n",
       "      <td>I fired Mr . Li today .</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>1</td>\n",
       "      <td>That's terrible . __eou__</td>\n",
       "      <td>sadness</td>\n",
       "      <td>inform</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1017 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:14.691746Z",
     "start_time": "2025-05-20T09:49:14.682864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# split the data into train and test\n",
    "train_df, test_df = train_test_split(hld, test_size=0.2, random_state=42, stratify=hld['hat'])\n"
   ],
   "id": "58c289453a62fbc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:49:15.394300Z",
     "start_time": "2025-05-20T09:49:14.873230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_ids, attention_masks = bert_tokenize_data(train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(train_df['hat'].values), token_ids, attention_masks, test_size=0.1)"
   ],
   "id": "e70d7ca38d0438c6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:51:51.155195Z",
     "start_time": "2025-05-20T09:49:15.435589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "epochs = 20\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, epochs)"
   ],
   "id": "8eac212dbbcdf59a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:18.864135\n",
      "Average Loss:     1.2349173627469852\n",
      "Time Taken:       0:00:07.859731\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:26.724293\n",
      "Average Loss:     1.38907498663122\n",
      "Average Accuracy: 0.45454545454545453\n",
      "Time Taken:       0:00:00.242029\n",
      "\n",
      "-------------------- Epoch 2 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:26.966701\n",
      "Average Loss:     0.950564538979012\n",
      "Time Taken:       0:00:07.335843\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:34.303693\n",
      "Average Loss:     1.1512981544841419\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.237203\n",
      "\n",
      "-------------------- Epoch 3 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:34.541569\n",
      "Average Loss:     0.6122964176794757\n",
      "Time Taken:       0:00:07.291063\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:41.833052\n",
      "Average Loss:     1.2775952585718848\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.234315\n",
      "\n",
      "-------------------- Epoch 4 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:42.067743\n",
      "Average Loss:     0.35018979992879473\n",
      "Time Taken:       0:00:07.310132\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:49.379542\n",
      "Average Loss:     1.4868500449440696\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.242002\n",
      "\n",
      "-------------------- Epoch 5 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:49.621973\n",
      "Average Loss:     0.18491758122716262\n",
      "Time Taken:       0:00:07.345973\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:56.968323\n",
      "Average Loss:     1.7006298357790166\n",
      "Average Accuracy: 0.5568181818181818\n",
      "Time Taken:       0:00:00.252590\n",
      "\n",
      "-------------------- Epoch 6 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:49:57.221333\n",
      "Average Loss:     0.10312578424244472\n",
      "Time Taken:       0:00:07.386973\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:04.608699\n",
      "Average Loss:     2.021823904731057\n",
      "Average Accuracy: 0.5113636363636364\n",
      "Time Taken:       0:00:00.240563\n",
      "\n",
      "-------------------- Epoch 7 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:04.849624\n",
      "Average Loss:     0.0745330027193236\n",
      "Time Taken:       0:00:07.296592\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:12.146628\n",
      "Average Loss:     2.120325215838172\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.211919\n",
      "\n",
      "-------------------- Epoch 8 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:12.358960\n",
      "Average Loss:     0.037379257603669946\n",
      "Time Taken:       0:00:07.308923\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:19.668315\n",
      "Average Loss:     2.338774708184329\n",
      "Average Accuracy: 0.5681818181818182\n",
      "Time Taken:       0:00:00.245101\n",
      "\n",
      "-------------------- Epoch 9 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:19.913840\n",
      "Average Loss:     0.029197875185080036\n",
      "Time Taken:       0:00:07.328405\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:27.243258\n",
      "Average Loss:     2.144968330860138\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.232590\n",
      "\n",
      "-------------------- Epoch 10 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:27.476234\n",
      "Average Loss:     0.027196534403154383\n",
      "Time Taken:       0:00:07.317927\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:34.795185\n",
      "Average Loss:     2.065658775242892\n",
      "Average Accuracy: 0.625\n",
      "Time Taken:       0:00:00.228768\n",
      "\n",
      "-------------------- Epoch 11 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:35.025228\n",
      "Average Loss:     0.019685126723387562\n",
      "Time Taken:       0:00:07.361552\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:42.387657\n",
      "Average Loss:     2.672658844427629\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.230421\n",
      "\n",
      "-------------------- Epoch 12 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:42.618505\n",
      "Average Loss:     0.01722630529041888\n",
      "Time Taken:       0:00:07.318670\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:49.937558\n",
      "Average Loss:     2.044422625013712\n",
      "Average Accuracy: 0.625\n",
      "Time Taken:       0:00:00.247960\n",
      "\n",
      "-------------------- Epoch 13 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:50.185919\n",
      "Average Loss:     0.016007865977767127\n",
      "Time Taken:       0:00:07.363075\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:57.550071\n",
      "Average Loss:     2.25461305227046\n",
      "Average Accuracy: 0.625\n",
      "Time Taken:       0:00:00.242512\n",
      "\n",
      "-------------------- Epoch 14 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:50:57.793604\n",
      "Average Loss:     0.012563804788363126\n",
      "Time Taken:       0:00:07.357064\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:05.151079\n",
      "Average Loss:     2.301826379515908\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.247677\n",
      "\n",
      "-------------------- Epoch 15 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:05.399140\n",
      "Average Loss:     0.013592272210466352\n",
      "Time Taken:       0:00:07.372182\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:12.771719\n",
      "Average Loss:     2.3228968652811917\n",
      "Average Accuracy: 0.5340909090909091\n",
      "Time Taken:       0:00:00.234884\n",
      "\n",
      "-------------------- Epoch 16 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:13.007040\n",
      "Average Loss:     0.010544363177082825\n",
      "Time Taken:       0:00:07.372765\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:20.380909\n",
      "Average Loss:     2.307640842077407\n",
      "Average Accuracy: 0.6136363636363636\n",
      "Time Taken:       0:00:00.211634\n",
      "\n",
      "-------------------- Epoch 17 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:20.592975\n",
      "Average Loss:     0.010845708060356707\n",
      "Time Taken:       0:00:07.395736\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:27.989153\n",
      "Average Loss:     2.313716796988791\n",
      "Average Accuracy: 0.625\n",
      "Time Taken:       0:00:00.223417\n",
      "\n",
      "-------------------- Epoch 18 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:28.213023\n",
      "Average Loss:     0.006738225594112326\n",
      "Time Taken:       0:00:07.355012\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:35.568426\n",
      "Average Loss:     2.624177883971821\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.222562\n",
      "\n",
      "-------------------- Epoch 19 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:35.791444\n",
      "Average Loss:     0.007024774758737412\n",
      "Time Taken:       0:00:07.387765\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:43.179569\n",
      "Average Loss:     2.319157627665184\n",
      "Average Accuracy: 0.6136363636363636\n",
      "Time Taken:       0:00:00.241711\n",
      "\n",
      "-------------------- Epoch 20 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:43.421669\n",
      "Average Loss:     0.0073620643284495755\n",
      "Time Taken:       0:00:07.497199\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-20 11:51:50.920496\n",
      "Average Loss:     2.335546393487179\n",
      "Average Accuracy: 0.625\n",
      "Time Taken:       0:00:00.233389\n",
      "\n",
      "Total training time: 0:02:32.290813\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:51:51.840685Z",
     "start_time": "2025-05-20T09:51:51.240253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "accuracy"
   ],
   "id": "d4f71d611d87e5b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.553921568627451)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:51:52.182357Z",
     "start_time": "2025-05-20T09:51:51.890132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = [\n",
    "\"We do not want to place ourselves in an inferior position . We are a good , small company---that's why you are interested .\",\n",
    "    \"We're having trouble with Bob .\",\n",
    "    \"Oh , I think I should try to read one . __eou__\",\n",
    "    \"To be frank , a letter of credit would increase the cost of my import . When I open a letter of credit with a bank , I have to pay a deposit . That will tie up my money and add to my cost .\",\n",
    "    \"I'm very glad to hear that .\",\n",
    "    \"OK ... OK ... Anyway . I will treat you as my best friend . I hope you can do the same .\",\n",
    "    \"I ’ m glad you are enjoying yourself .\"\n",
    "]\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=3, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "preds, confidences"
   ],
   "id": "fdc47becb2b05a85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2, 4, 2, 3, 4, 3],\n",
       " [0.9987348914146423,\n",
       "  0.9988678693771362,\n",
       "  0.9978197813034058,\n",
       "  0.9986592531204224,\n",
       "  0.9983394145965576,\n",
       "  0.998264729976654,\n",
       "  0.9989126920700073])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-20T09:51:52.330746Z",
     "start_time": "2025-05-20T09:51:52.314639Z"
    }
   },
   "cell_type": "code",
   "source": "test_df",
   "id": "ed82938f34cd7ff5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     turn                                          utterance     emotion  \\\n",
       "299     0  My father ’ s angry face always makes my blood...        fear   \n",
       "319     1                       What are you talking about ?  no_emotion   \n",
       "688     4  I couldn ’ t agree more . That ’ s an ideal pl...   happiness   \n",
       "665     0                            How's your girlfriend ?  no_emotion   \n",
       "955     7  I hope to make 4,000 yuan a month for supporti...  no_emotion   \n",
       "..    ...                                                ...         ...   \n",
       "890     4  What kinds of channels can you use in e-commer...  no_emotion   \n",
       "340     5  That's quite a compliment coming from you . __...   happiness   \n",
       "514     5                 Why not now ? I'm hungry . __eou__   happiness   \n",
       "326     0                   He has come to life in the end .  no_emotion   \n",
       "314     4  I was in such a panic at that time . Fortunate...  no_emotion   \n",
       "\n",
       "           act  hat  \n",
       "299     inform    1  \n",
       "319   question    1  \n",
       "688     inform    0  \n",
       "665   question    1  \n",
       "955  directive    1  \n",
       "..         ...  ...  \n",
       "890   question    1  \n",
       "340     inform    1  \n",
       "514     inform    1  \n",
       "326     inform    1  \n",
       "314     inform    1  \n",
       "\n",
       "[204 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>My father ’ s angry face always makes my blood...</td>\n",
       "      <td>fear</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1</td>\n",
       "      <td>What are you talking about ?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>4</td>\n",
       "      <td>I couldn ’ t agree more . That ’ s an ideal pl...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0</td>\n",
       "      <td>How's your girlfriend ?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>7</td>\n",
       "      <td>I hope to make 4,000 yuan a month for supporti...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>directive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>4</td>\n",
       "      <td>What kinds of channels can you use in e-commer...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>5</td>\n",
       "      <td>That's quite a compliment coming from you . __...</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>5</td>\n",
       "      <td>Why not now ? I'm hungry . __eou__</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0</td>\n",
       "      <td>He has come to life in the end .</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4</td>\n",
       "      <td>I was in such a panic at that time . Fortunate...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b2a2e4b9deb1a83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "678baa7219d18899"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
