{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-21T16:59:56.404022Z",
     "start_time": "2025-05-21T16:59:53.247614Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    RobertaForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    AutoConfig,\n",
    ")\n",
    "\n",
    "from bert_util import bert_tokenize_data, tensor_train_test_split, train_bert_model, model_predict, get_data_loader\n",
    "import pandas as pd\n",
    "from util import eda_augment_dataset, get_dataframe_from_json\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emiliano/Desktop/Università/Human Language Technologies/Project/HLT Project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-21 18:59:55.328457: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-21 18:59:55.335225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747846795.343445   16451 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747846795.345906   16451 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747846795.352178   16451 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747846795.352185   16451 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747846795.352186   16451 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747846795.352187   16451 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-21 18:59:55.355184: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T16:59:56.477281Z",
     "start_time": "2025-05-21T16:59:56.465543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df = pd.read_json('../train_dataset.json', lines=False)\n",
    "test_df = pd.read_json('../test_dataset.json', lines=False)\n",
    "train_df"
   ],
   "id": "d16978a9f79dc67d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     turn                                          utterance     emotion  \\\n",
       "0       3                               I'll take one, too.    happiness   \n",
       "1       8  You know, we are superior to other clothes com...  no_emotion   \n",
       "2       5                          Her new boyfriend, right?  no_emotion   \n",
       "3       9  How about recommending him to use the storage ...  no_emotion   \n",
       "4       1   Oh, a bouquet of flowers. It's very kind of you.    surprise   \n",
       "..    ...                                                ...         ...   \n",
       "808     0                    I prefer potatoes to eggplants.  no_emotion   \n",
       "809     0  Mr. Smith, I would like to get right to the po...  no_emotion   \n",
       "810     4                                              Yeah?  no_emotion   \n",
       "811     0                             I am so bored all day.  no_emotion   \n",
       "812     2                           Do you play much tennis?  no_emotion   \n",
       "\n",
       "            act  hat  \n",
       "0        inform    0  \n",
       "1        inform    3  \n",
       "2    commissive    1  \n",
       "3     directive    4  \n",
       "4    commissive    1  \n",
       "..          ...  ...  \n",
       "808      inform    0  \n",
       "809    question    1  \n",
       "810    question    1  \n",
       "811      inform    0  \n",
       "812    question    1  \n",
       "\n",
       "[813 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I'll take one, too.</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>You know, we are superior to other clothes com...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Her new boyfriend, right?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>How about recommending him to use the storage ...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>directive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh, a bouquet of flowers. It's very kind of you.</td>\n",
       "      <td>surprise</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0</td>\n",
       "      <td>I prefer potatoes to eggplants.</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Smith, I would like to get right to the po...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>4</td>\n",
       "      <td>Yeah?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0</td>\n",
       "      <td>I am so bored all day.</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>2</td>\n",
       "      <td>Do you play much tennis?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T16:59:59.631560Z",
     "start_time": "2025-05-21T16:59:59.342707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "token_ids, attention_masks = bert_tokenize_data(tokenizer, train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(train_df['hat'].values), token_ids, attention_masks, test_size=0.1)"
   ],
   "id": "8fcb7cb11912b8f0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T17:02:02.284850Z",
     "start_time": "2025-05-21T17:00:05.258141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)\n",
    "epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, epochs)"
   ],
   "id": "e019bcd53e365530",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:05.844753\n",
      "Average Loss:     1.3238509621309198\n",
      "Time Taken:       0:00:11.459815\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:17.304937\n",
      "Average Loss:     1.4233713150024414\n",
      "Average Accuracy: 0.4090909090909091\n",
      "Time Taken:       0:00:00.375181\n",
      "\n",
      "-------------------- Epoch 2 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:17.680473\n",
      "Average Loss:     1.1604303681980008\n",
      "Time Taken:       0:00:11.280846\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:28.961643\n",
      "Average Loss:     1.4465822712941603\n",
      "Average Accuracy: 0.5227272727272727\n",
      "Time Taken:       0:00:00.380521\n",
      "\n",
      "-------------------- Epoch 3 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:29.342597\n",
      "Average Loss:     0.940253781883613\n",
      "Time Taken:       0:00:11.298843\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:40.641800\n",
      "Average Loss:     1.4278808723796497\n",
      "Average Accuracy: 0.5113636363636364\n",
      "Time Taken:       0:00:00.381788\n",
      "\n",
      "-------------------- Epoch 4 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:41.023979\n",
      "Average Loss:     0.7113457945701869\n",
      "Time Taken:       0:00:11.255321\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:52.279650\n",
      "Average Loss:     1.3762859295714984\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.376215\n",
      "\n",
      "-------------------- Epoch 5 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:00:52.656206\n",
      "Average Loss:     0.5161742556273289\n",
      "Time Taken:       0:00:11.280860\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:03.937512\n",
      "Average Loss:     1.7611023174090819\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.390480\n",
      "\n",
      "-------------------- Epoch 6 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:04.328406\n",
      "Average Loss:     0.3706926746374887\n",
      "Time Taken:       0:00:11.250896\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:15.579644\n",
      "Average Loss:     1.7944883975115689\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.370760\n",
      "\n",
      "-------------------- Epoch 7 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:15.950796\n",
      "Average Loss:     0.2538233733654994\n",
      "Time Taken:       0:00:11.185947\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:27.137114\n",
      "Average Loss:     1.986384624784643\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.374364\n",
      "\n",
      "-------------------- Epoch 8 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:27.511881\n",
      "Average Loss:     0.18982984799810726\n",
      "Time Taken:       0:00:11.194071\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:38.706321\n",
      "Average Loss:     2.1511202508753\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.377362\n",
      "\n",
      "-------------------- Epoch 9 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:39.084061\n",
      "Average Loss:     0.123393300657525\n",
      "Time Taken:       0:00:11.222197\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:50.306671\n",
      "Average Loss:     2.1624369241974573\n",
      "Average Accuracy: 0.5795454545454546\n",
      "Time Taken:       0:00:00.377717\n",
      "\n",
      "-------------------- Epoch 10 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:01:50.684775\n",
      "Average Loss:     0.08519661912957774\n",
      "Time Taken:       0:00:11.221170\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:02:01.906306\n",
      "Average Loss:     2.4159267273816196\n",
      "Average Accuracy: 0.5454545454545454\n",
      "Time Taken:       0:00:00.377194\n",
      "\n",
      "Total training time: 0:01:56.439129\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T17:06:11.920066Z",
     "start_time": "2025-05-21T17:06:11.507215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "test_texts = test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "preds_array = np.array(preds)\n",
    "\n",
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "f8ae13be2e62ee91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.49      0.45      0.47        40\n",
      "       white       0.74      0.75      0.75       110\n",
      "       black       0.43      0.43      0.43        23\n",
      "      yellow       0.35      0.32      0.33        19\n",
      "       green       0.27      0.33      0.30        12\n",
      "\n",
      "    accuracy                           0.59       204\n",
      "   macro avg       0.46      0.46      0.46       204\n",
      "weighted avg       0.59      0.59      0.59       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T17:06:27.068189Z",
     "start_time": "2025-05-21T17:06:27.055319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "augmented_train_df = pd.read_json('../eda_train_dataset.json', lines=False)\n",
    "augmented_train_df"
   ],
   "id": "ab4f2f558766c9b1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      turn                                          utterance     emotion  \\\n",
       "0        3                               I'll take one, too.    happiness   \n",
       "1        8  You know, we are superior to other clothes com...  no_emotion   \n",
       "2        5                          Her new boyfriend, right?  no_emotion   \n",
       "3        9  How about recommending him to use the storage ...  no_emotion   \n",
       "4        1   Oh, a bouquet of flowers. It's very kind of you.    surprise   \n",
       "...    ...                                                ...         ...   \n",
       "3738     0                       i am wholly so bored all day  no_emotion   \n",
       "3739     0                         i am so bored all daylight  no_emotion   \n",
       "3740     0                              i am so bored all day  no_emotion   \n",
       "3741     0                          i am so bored all daytime  no_emotion   \n",
       "3742     0                              day am so bored all i  no_emotion   \n",
       "\n",
       "             act  hat  \n",
       "0         inform    0  \n",
       "1         inform    3  \n",
       "2     commissive    1  \n",
       "3      directive    4  \n",
       "4     commissive    1  \n",
       "...          ...  ...  \n",
       "3738      inform    0  \n",
       "3739      inform    0  \n",
       "3740      inform    0  \n",
       "3741      inform    0  \n",
       "3742      inform    0  \n",
       "\n",
       "[3743 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I'll take one, too.</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>You know, we are superior to other clothes com...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Her new boyfriend, right?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>How about recommending him to use the storage ...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>directive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh, a bouquet of flowers. It's very kind of you.</td>\n",
       "      <td>surprise</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>0</td>\n",
       "      <td>i am wholly so bored all day</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>0</td>\n",
       "      <td>i am so bored all daylight</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>0</td>\n",
       "      <td>i am so bored all day</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>0</td>\n",
       "      <td>i am so bored all daytime</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>0</td>\n",
       "      <td>day am so bored all i</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3743 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T17:15:25.922205Z",
     "start_time": "2025-05-21T17:06:29.973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "token_ids, attention_masks = bert_tokenize_data(tokenizer, augmented_train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(augmented_train_df['hat'].values), token_ids, attention_masks, test_size=0.1)\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)\n",
    "epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_training_steps = epochs * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, epochs)"
   ],
   "id": "2cc84e819155f687",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:06:31.134568\n",
      "Average Loss:     0.8155961225778219\n",
      "Time Taken:       0:00:51.257857\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:07:22.392744\n",
      "Average Loss:     1.2723816867838516\n",
      "Average Accuracy: 0.5227963525835867\n",
      "Time Taken:       0:00:01.541842\n",
      "\n",
      "-------------------- Epoch 2 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:07:23.934986\n",
      "Average Loss:     0.2834358179268168\n",
      "Time Taken:       0:00:51.502900\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:08:15.438223\n",
      "Average Loss:     2.9783911045561444\n",
      "Average Accuracy: 0.44034954407294835\n",
      "Time Taken:       0:00:01.559063\n",
      "\n",
      "-------------------- Epoch 3 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:08:16.997662\n",
      "Average Loss:     0.1705245903423255\n",
      "Time Taken:       0:00:52.321096\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:09:09.319149\n",
      "Average Loss:     1.1702914745943185\n",
      "Average Accuracy: 0.7895136778115501\n",
      "Time Taken:       0:00:01.573241\n",
      "\n",
      "-------------------- Epoch 4 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:09:10.892858\n",
      "Average Loss:     0.10866743838663419\n",
      "Time Taken:       0:00:51.744202\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:10:02.637429\n",
      "Average Loss:     1.2816877687285515\n",
      "Average Accuracy: 0.8054711246200608\n",
      "Time Taken:       0:00:01.533489\n",
      "\n",
      "-------------------- Epoch 5 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:10:04.171330\n",
      "Average Loss:     0.061872851504983534\n",
      "Time Taken:       0:00:52.126274\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:10:56.297997\n",
      "Average Loss:     1.6957185150302472\n",
      "Average Accuracy: 0.7678571428571429\n",
      "Time Taken:       0:00:01.575012\n",
      "\n",
      "-------------------- Epoch 6 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:10:57.873415\n",
      "Average Loss:     0.04830449556648696\n",
      "Time Taken:       0:00:51.941478\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:11:49.815295\n",
      "Average Loss:     0.8258323907211889\n",
      "Average Accuracy: 0.8776595744680851\n",
      "Time Taken:       0:00:01.561234\n",
      "\n",
      "-------------------- Epoch 7 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:11:51.376933\n",
      "Average Loss:     0.025523319378330134\n",
      "Time Taken:       0:00:51.733351\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:12:43.110668\n",
      "Average Loss:     0.7092497280468802\n",
      "Average Accuracy: 0.9042553191489362\n",
      "Time Taken:       0:00:01.553662\n",
      "\n",
      "-------------------- Epoch 8 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:12:44.664730\n",
      "Average Loss:     0.015031929276069939\n",
      "Time Taken:       0:00:52.509378\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:13:37.174599\n",
      "Average Loss:     1.2391663965567243\n",
      "Average Accuracy: 0.8377659574468085\n",
      "Time Taken:       0:00:01.578196\n",
      "\n",
      "-------------------- Epoch 9 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:13:38.753245\n",
      "Average Loss:     0.00922760956466083\n",
      "Time Taken:       0:00:52.034847\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:14:30.788481\n",
      "Average Loss:     1.134712014578907\n",
      "Average Accuracy: 0.8430851063829787\n",
      "Time Taken:       0:00:01.556256\n",
      "\n",
      "-------------------- Epoch 10 --------------------\n",
      "\n",
      "Training:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:14:32.345150\n",
      "Average Loss:     0.008264106123118784\n",
      "Time Taken:       0:00:52.018649\n",
      "\n",
      "Validation:\n",
      "---------\n",
      "Start Time:       2025-05-21 19:15:24.364167\n",
      "Average Loss:     1.2447020975935417\n",
      "Average Accuracy: 0.8294072948328267\n",
      "Time Taken:       0:00:01.556439\n",
      "\n",
      "Total training time: 0:08:54.786457\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T17:15:26.347591Z",
     "start_time": "2025-05-21T17:15:25.937426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "preds_array = np.array(preds)\n",
    "\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "3bb53c14366b8954",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.54      0.47      0.51        40\n",
      "       white       0.66      0.84      0.74       110\n",
      "       black       0.36      0.22      0.27        23\n",
      "      yellow       0.54      0.37      0.44        19\n",
      "       green       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61       204\n",
      "   macro avg       0.49      0.40      0.42       204\n",
      "weighted avg       0.57      0.61      0.58       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "20bd5806aa9130ec"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
