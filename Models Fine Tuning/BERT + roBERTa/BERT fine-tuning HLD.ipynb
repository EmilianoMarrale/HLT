{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from util import get_dataframe_from_json\n",
    "from sklearn.metrics import classification_report\n",
    "from bert_util import bert_tokenize_data, tensor_train_test_split, train_bert_model, model_predict, get_data_loader, \\\n",
    "    train_pipeline, randomized_cv_search\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from bert_util import scoring_fn\n",
    "os.environ[\"USE_TF\"] = \"0\""
   ],
   "id": "e79ad018e19671f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 16:16:02,433\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-05-26 16:16:02,669\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Normal Hand-Labeled Dataset",
   "id": "51c5e17db8716ba2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:40:43.400518353Z",
     "start_time": "2025-05-26T14:16:02.749539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "normal_train_df = pd.read_json('../normal_train_dataset.json', lines=False)\n",
    "normal_test_df = pd.read_json('../normal_test_dataset.json', lines=False)\n",
    "normal_train_df"
   ],
   "id": "4d6cb2e52215c782",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     turn                                          utterance     emotion  \\\n",
       "0       3                               I'll take one, too.    happiness   \n",
       "1       8  You know, we are superior to other clothes com...  no_emotion   \n",
       "2       5                          Her new boyfriend, right?  no_emotion   \n",
       "3       9  How about recommending him to use the storage ...  no_emotion   \n",
       "4       1   Oh, a bouquet of flowers. It's very kind of you.    surprise   \n",
       "..    ...                                                ...         ...   \n",
       "808     0                    I prefer potatoes to eggplants.  no_emotion   \n",
       "809     0  Mr. Smith, I would like to get right to the po...  no_emotion   \n",
       "810     4                                              Yeah?  no_emotion   \n",
       "811     0                             I am so bored all day.  no_emotion   \n",
       "812     2                           Do you play much tennis?  no_emotion   \n",
       "\n",
       "            act  hat  \n",
       "0        inform    0  \n",
       "1        inform    3  \n",
       "2    commissive    1  \n",
       "3     directive    4  \n",
       "4    commissive    1  \n",
       "..          ...  ...  \n",
       "808      inform    0  \n",
       "809    question    1  \n",
       "810    question    1  \n",
       "811      inform    0  \n",
       "812    question    1  \n",
       "\n",
       "[813 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn</th>\n",
       "      <th>utterance</th>\n",
       "      <th>emotion</th>\n",
       "      <th>act</th>\n",
       "      <th>hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>I'll take one, too.</td>\n",
       "      <td>happiness</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>You know, we are superior to other clothes com...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Her new boyfriend, right?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>How about recommending him to use the storage ...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>directive</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh, a bouquet of flowers. It's very kind of you.</td>\n",
       "      <td>surprise</td>\n",
       "      <td>commissive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0</td>\n",
       "      <td>I prefer potatoes to eggplants.</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>0</td>\n",
       "      <td>Mr. Smith, I would like to get right to the po...</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>4</td>\n",
       "      <td>Yeah?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0</td>\n",
       "      <td>I am so bored all day.</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>inform</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>2</td>\n",
       "      <td>Do you play much tennis?</td>\n",
       "      <td>no_emotion</td>\n",
       "      <td>question</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>813 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Baseline BERT over the Normal Hand-Labeled Dataset",
   "id": "108d69a16f91ad58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_ids, attention_masks = bert_tokenize_data(tokenizer, normal_train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(normal_train_df['hat'].values), token_ids, attention_masks, test_size=0.1)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "configs = {\n",
    "        \"epochs\": 10,\n",
    "        \"clip_grad_norm\": 1.0,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_delta\": 0.1,\n",
    "    }\n",
    "\n",
    "num_training_steps = 10 * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, configs)"
   ],
   "id": "e70d7ca38d0438c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:12:42.762171Z",
     "start_time": "2025-05-25T18:12:42.435958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = normal_test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = normal_test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)"
   ],
   "id": "d4f71d611d87e5b5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:12:42.778183Z",
     "start_time": "2025-05-25T18:12:42.773559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "preds_array = np.array(preds)\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "9b2a2e4b9deb1a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.53      0.50      0.51        40\n",
      "       white       0.75      0.75      0.75       110\n",
      "       black       0.33      0.26      0.29        23\n",
      "      yellow       0.48      0.63      0.55        19\n",
      "       green       0.17      0.17      0.17        12\n",
      "\n",
      "    accuracy                           0.60       204\n",
      "   macro avg       0.45      0.46      0.45       204\n",
      "weighted avg       0.60      0.60      0.60       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# HyperParameter Tuning over the Normal Hand-Labeled Dataset",
   "id": "b7d3e1df4200b529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model():\n",
    "    return BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "best_model, best_config, best_score = randomized_cv_search(build_model, tokenizer, normal_train_df['utterance'], normal_train_df['hat'], num_folds=5, num_samples=20, use_lora=True)\n"
   ],
   "id": "f80560c9fd63836e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T18:54:55.162652Z",
     "start_time": "2025-05-25T18:54:54.615275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tids, amids = bert_tokenize_data(tokenizer, pd.Series(normal_test_df['utterance'].values), max_length=best_config[\"tokenizer_max_length\"])\n",
    "val_dataloader = get_data_loader(tids, amids, batch_size=best_config[\"dataloader_batch_size\"], shuffle=False)\n",
    "print(f\"Best config: {best_config}\")\n",
    "score = scoring_fn(best_model, val_dataloader, normal_test_df['hat'].values)\n",
    "#Best config: {'epochs': 15, 'model_dropout': 0.3, 'optimizer_lr': 0.0001, 'scheduler_warmup_steps': 200, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.1, 'tokenizer_max_length': 128, 'dataloader_batch_size': 16, 'clip_grad_norm': 2.0, 'early_stopping_patience': 10, 'early_stopping_delta': 0.01, 'scheduler_type': 'constant', 'optimizer_type': 'AdamW', 'weight_decay': 0.0001}"
   ],
   "id": "23a232e9aebc0697",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'epochs': 30, 'model_dropout': 0.1, 'optimizer_lr': 0.001, 'scheduler_warmup_steps': 0, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.05, 'tokenizer_max_length': 128, 'dataloader_batch_size': 32, 'clip_grad_norm': 1.0, 'early_stopping_patience': 10, 'early_stopping_delta': 0.01, 'scheduler_type': 'linear', 'optimizer_type': 'AdamW', 'weight_decay': 0.0001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.57      0.42      0.49        40\n",
      "       white       0.70      0.82      0.76       110\n",
      "       black       0.67      0.09      0.15        23\n",
      "      yellow       0.28      0.53      0.36        19\n",
      "       green       0.29      0.17      0.21        12\n",
      "\n",
      "    accuracy                           0.59       204\n",
      "   macro avg       0.50      0.40      0.39       204\n",
      "weighted avg       0.61      0.59      0.57       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EDA Augmented Hand-Labeled Dataset",
   "id": "3b0d37bc4ec9baa7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:18:09.810324Z",
     "start_time": "2025-05-26T14:18:09.799918Z"
    }
   },
   "cell_type": "code",
   "source": "augmented_train_df = pd.read_json('../eda_train_dataset.json', lines=False)",
   "id": "12094416d5c6987e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_ids, attention_masks = bert_tokenize_data(tokenizer, augmented_train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(augmented_train_df['hat'].values), token_ids, attention_masks, test_size=0.1)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "configs = {\n",
    "        \"epochs\": 10,\n",
    "        \"clip_grad_norm\": 1.0,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_delta\": 0.1,\n",
    "    }\n",
    "\n",
    "num_training_steps = 10 * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, configs)"
   ],
   "id": "7a72c4f6b580b1d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T17:37:27.269054Z",
     "start_time": "2025-05-25T17:37:26.932479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = normal_test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = normal_test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "preds_array = np.array(preds)\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "c77ace27fdba0741",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.63      0.47      0.54        40\n",
      "       white       0.66      0.89      0.76       110\n",
      "       black       0.29      0.09      0.13        23\n",
      "      yellow       0.78      0.37      0.50        19\n",
      "       green       0.56      0.42      0.48        12\n",
      "\n",
      "    accuracy                           0.64       204\n",
      "   macro avg       0.58      0.45      0.48       204\n",
      "weighted avg       0.62      0.64      0.60       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### HyperParameter Tuning over the EDA Augmented Hand-Labeled Dataset",
   "id": "d1bf8d998a77b114"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model():\n",
    "    return BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "best_model, best_config, best_score = randomized_cv_search(build_model, tokenizer, augmented_train_df['utterance'], augmented_train_df['hat'], num_folds=5, num_samples=20, use_lora=True)"
   ],
   "id": "f31099ab3a42785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:36:10.160870869Z",
     "start_time": "2025-05-25T17:55:46.550309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tids, amids = bert_tokenize_data(tokenizer, pd.Series(normal_test_df['utterance'].values), max_length=best_config[\"tokenizer_max_length\"])\n",
    "val_dataloader = get_data_loader(tids, amids, batch_size=best_config[\"dataloader_batch_size\"], shuffle=False)\n",
    "print(f\"Best config: {best_config}\")\n",
    "score = scoring_fn(best_model, val_dataloader, normal_test_df['hat'].values)\n",
    "# Best config: {'epochs': 15, 'model_dropout': 0.3, 'optimizer_lr': 0.0001, 'scheduler_warmup_steps': 200, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.1, 'tokenizer_max_length': 128, 'dataloader_batch_size': 16, 'clip_grad_norm': 2.0, 'early_stopping_patience': 10, 'early_stopping_delta': 0.01, 'scheduler_type': 'constant', 'optimizer_type': 'AdamW', 'weight_decay': 0.0001}"
   ],
   "id": "ec4222ce2d7ff39c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'epochs': 15, 'model_dropout': 0.3, 'optimizer_lr': 0.0001, 'scheduler_warmup_steps': 200, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.1, 'tokenizer_max_length': 128, 'dataloader_batch_size': 16, 'clip_grad_norm': 2.0, 'early_stopping_patience': 10, 'early_stopping_delta': 0.01, 'scheduler_type': 'constant', 'optimizer_type': 'AdamW', 'weight_decay': 0.0001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.55      0.30      0.39        40\n",
      "       white       0.64      0.88      0.74       110\n",
      "       black       0.40      0.26      0.32        23\n",
      "      yellow       0.55      0.32      0.40        19\n",
      "       green       0.50      0.17      0.25        12\n",
      "\n",
      "    accuracy                           0.60       204\n",
      "   macro avg       0.53      0.39      0.42       204\n",
      "weighted avg       0.58      0.60      0.56       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Randomized Search for Hyperparameter Tuning usage example",
   "id": "2c6e51b7f17b3c20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BERT over the Automated Labeled Dataset",
   "id": "df88265d66c1334b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:37:09.696922Z",
     "start_time": "2025-05-26T14:37:09.681029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ald_train_df = pd.read_json('../ald_train_dataset.json', lines=False)\n",
    "ald_test_df = pd.read_json('../ald_test_dataset.json', lines=False)"
   ],
   "id": "cae3f54e46c49f2e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "token_ids, attention_masks = bert_tokenize_data(tokenizer, ald_train_df['utterance'].values)\n",
    "train_dataloader, val_dataloader = tensor_train_test_split(torch.tensor(ald_train_df['hat'].values), token_ids, attention_masks, test_size=0.1)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "\n",
    "configs = {\n",
    "        \"epochs\": 10,\n",
    "        \"clip_grad_norm\": 1.0,\n",
    "        \"early_stopping_patience\": 3,\n",
    "        \"early_stopping_delta\": 0.1,\n",
    "    }\n",
    "\n",
    "num_training_steps = 10 * len(train_dataloader)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps)\n",
    "\n",
    "model = train_bert_model(model, optimizer, scheduler, train_dataloader, val_dataloader, configs)"
   ],
   "id": "f37fb0cff2d5afa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:43:33.452352Z",
     "start_time": "2025-05-26T14:43:31.845688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = ald_test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = ald_test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "preds_array = np.array(preds)\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "e26e2c10b085d56b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.78      0.73      0.75       200\n",
      "       white       0.45      0.33      0.38       200\n",
      "       black       0.60      0.48      0.54       200\n",
      "      yellow       0.51      0.70      0.59       200\n",
      "       green       0.59      0.66      0.62       200\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.58      0.58      0.58      1000\n",
      "weighted avg       0.58      0.58      0.58      1000\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_model():\n",
    "    return BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "best_model, best_config, best_score = randomized_cv_search(build_model, tokenizer, ald_train_df['utterance'], ald_train_df['hat'], num_folds=2, num_samples=20, use_lora=True)\n"
   ],
   "id": "6512d1475d97e995",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T20:36:10.174947934Z",
     "start_time": "2025-05-25T18:07:47.314049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bert_util import scoring_fn\n",
    "tids, amids = bert_tokenize_data(tokenizer, pd.Series(ald_test_df['utterance'].values), max_length=best_config[\"tokenizer_max_length\"])\n",
    "val_dataloader = get_data_loader(tids, amids, batch_size=best_config[\"dataloader_batch_size\"], shuffle=False)\n",
    "print(f\"Best config: {best_config}\")\n",
    "score = scoring_fn(best_model, val_dataloader, ald_test_df['hat'].values)"
   ],
   "id": "ae6861a3c6aacf9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'epochs': 15, 'model_dropout': 0.3, 'optimizer_lr': 0.0001, 'scheduler_warmup_steps': 200, 'lora_r': 4, 'lora_alpha': 32, 'lora_dropout': 0.1, 'tokenizer_max_length': 128, 'dataloader_batch_size': 16, 'clip_grad_norm': 2.0, 'early_stopping_patience': 10, 'early_stopping_delta': 0.01, 'scheduler_type': 'constant', 'optimizer_type': 'AdamW', 'weight_decay': 0.0001}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.40      0.40      0.40        40\n",
      "       white       0.69      0.80      0.74       110\n",
      "       black       0.33      0.17      0.23        23\n",
      "      yellow       0.29      0.26      0.28        19\n",
      "       green       0.25      0.17      0.20        12\n",
      "\n",
      "    accuracy                           0.56       204\n",
      "   macro avg       0.39      0.36      0.37       204\n",
      "weighted avg       0.53      0.56      0.54       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing the model over the Normal Hand-Labeled test set",
   "id": "3858e562fc8ea488"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T14:44:09.903919Z",
     "start_time": "2025-05-26T14:44:09.554696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_texts = normal_test_df['utterance'].values\n",
    "serie = pd.Series(test_texts)\n",
    "tids, amids = bert_tokenize_data(tokenizer, serie, max_length=64)\n",
    "dl = get_data_loader(tids, amids, batch_size=5, shuffle=False)\n",
    "preds, confidences = model_predict(model, dl)\n",
    "labels_flat = normal_test_df['hat'].values.flatten()\n",
    "accuracy = np.sum(preds == labels_flat) / len(labels_flat)\n",
    "hat_map = {\n",
    "    0: \"red\",\n",
    "    1: \"white\",\n",
    "    2: \"black\",\n",
    "    3: \"yellow\",\n",
    "    4: \"green\",\n",
    "}\n",
    "preds_array = np.array(preds)\n",
    "print(classification_report(labels_flat, preds_array, target_names=list(hat_map.values())))"
   ],
   "id": "b908f74d231c34d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.36      0.30      0.33        40\n",
      "       white       0.65      0.45      0.53       110\n",
      "       black       0.15      0.13      0.14        23\n",
      "      yellow       0.22      0.63      0.32        19\n",
      "       green       0.11      0.17      0.13        12\n",
      "\n",
      "    accuracy                           0.39       204\n",
      "   macro avg       0.30      0.34      0.29       204\n",
      "weighted avg       0.46      0.39      0.41       204\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7bbacd2a1ff9e4e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
